<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Sparkov Generator</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/night.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
					<section data-markdown>
							<textarea data-template>
							### Sparkov Generator Models

							##### Making up abstracts with Arxiv and Spark
							</textarea>
						</section>
						<section data-markdown>
								<textarea data-template>
								### The Data

								- Around 6,000 papers
								- From January 2018
								- Range of subjects
								</textarea>
							</section>
							<section data-markdown>
								<textarea data-template>
								### Goal: Create new abstracts from our dataset
								- Use a markov text generation model trained on the abstracts
								- Create a series of new abstracts
								- Determine if people can tell the difference between real and fake 
								</textarea>
						</section>
						<section data-markdown>
							<textarea data-template>
							### Markov Text Generator Explanation
							- What words most likely come after this other word? 
							</textarea>
					</section>
						<section data-markdown>
								<textarea data-template>
								### Use spark to pull

								Use spark to: 
								1. Titles 
								2. Abstracts
								</textarea>
						</section>
						<section data-markdown>
							<textarea data-template>
							### Per-Subject Generators?

							- Subject not available in raw documents
							- Might make abstracts more convincing if they're trained in groups based on subject
							</textarea>
					</section>
					<section data-markdown>
						<textarea data-template>
						### The Arxiv website has the subject!

						![](image/subject_css.png)

						</textarea>
				</section>
						<section data-markdown>
								<textarea data-template>

						![](image/go_get_it.gif)
						
								</textarea>
						</section>
						<section data-markdown>
								<textarea data-template>
						- The url is actually determined by the ID in the filenames.
						- Instead of 1801_10602 it's 1801.10602
								</textarea>
						</section>
						<section data-markdown>
								<textarea data-template>
						- What subjects would most likely work out? (Which have high sample size)
						- TODO: INSERT BAR GRAPH SHOWING DISTRIBUTION OF SUBJECTS
								</textarea>
						</section>
						<section data-markdown>
								<textarea data-template>
						- TODO: Insert 3-5 subjects we decided to use, and their counts
								</textarea>
						</section>
						<section data-markdown>
								<textarea data-template>
								### Show example markov generated doc 
								</textarea>
						</section>
						<section data-markdown>
								<textarea data-template>
								### But how'd we do?
								- Created surveymonkey polling students to determine which paper was real 
								- [INSERT NUMBER OF PEOPLE] participated
								</textarea>
						</section>
						<section data-markdown>
								<textarea data-template>
									[TODO: INSERT SCREENSHOT OF SURVEYMONKEY]
								</textarea>
						</section>
						<section data-markdown>
								<textarea data-template>
									Display results here textually
									include graphic
								</textarea>
						</section>
						<section data-markdown>
								<textarea data-template>
								## Takeaways
								</textarea>
						</section>
						<section data-markdown>
							<textarea data-template>
							### Decade-based Models

							- Make one model per each decade 
							- Seperate quizzes made of real and generated abstracts over the years
							- Does it get harder distinguish technobabble from legitimate as fields become more specialized?
							</textarea>
					</section>	
					<section data-markdown>
						<textarea data-template>
						### Make a GAN

						- Some kind of adversarial model, one trying to determine if a paper is legitimate or not
						- The other trying to make progressively better papers
						- "Test" every once in a while by creating a survey and seeing how people do on it 
						- Goal of making results no better than random chance guess. 
						</textarea>
				</section>	
				<section data-markdown>
					<textarea data-template>
					### All of this requires 

					- More data
					- Potentially more processing power

					![](image/unlimited.gif)		
					</textarea>
			</section>						
						<section data-markdown>
								<textarea data-template>
										![](image/go_home.gif)		
								</textarea>
						</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
